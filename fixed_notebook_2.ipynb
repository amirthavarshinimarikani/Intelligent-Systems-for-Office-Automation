{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7VcXcgP0B4Hf",
    "outputId": "a5f05cac-3b4e-4059-800c-492c7a8b4187"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting summa\n",
      "  Downloading summa-1.2.0.tar.gz (54 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.12/dist-packages (from summa) (1.16.3)\n",
      "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy>=0.19->summa) (2.0.2)\n",
      "Building wheels for collected packages: summa\n",
      "  Building wheel for summa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for summa: filename=summa-1.2.0-py3-none-any.whl size=54387 sha256=91416e03efc7381a7d593d9acd11cb86f68b4df439033572dcf8fe31c2ef2547\n",
      "  Stored in directory: /root/.cache/pip/wheels/70/26/84/58df5a55ebde6fd802666b6ac0b86909ecd018a2702b89d13c\n",
      "Successfully built summa\n",
      "Installing collected packages: summa\n",
      "Successfully installed summa-1.2.0\n",
      "### TextRank (Extractive) Summary ###\n",
      "sentences are weighted by their semantic similarity.\n",
      "algorithm similar to PageRank to rank the importance of each sentence.\n"
     ]
    }
   ],
   "source": [
    "!pip install summa\n",
    "\n",
    "from summa import summarizer\n",
    "\n",
    "text = \"\"\"\n",
    "The TextRank algorithm is an unsupervised, graph-based ranking model for text processing.\n",
    "It works by building a graph where sentences are nodes (vertices) and the edges between\n",
    "sentences are weighted by their semantic similarity. This similarity is often calculated\n",
    "using techniques like cosine similarity on word vectors. The process then applies an\n",
    "algorithm similar to PageRank to rank the importance of each sentence. The sentences\n",
    "with the highest scores are extracted to form the final summary. This approach is highly\n",
    "efficient as it avoids the need for massive labeled training data and complex deep learning\n",
    "architectures, making it a reliable choice for legal or technical documents where factual\n",
    "accuracy is paramount.\n",
    "\"\"\"\n",
    "textrank_summary = summarizer.summarize(text, ratio=0.2)\n",
    "\n",
    "print(\"### TextRank (Extractive) Summary ###\")\n",
    "print(textrank_summary)\n",
    "# Output will be sentences lifted directly from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8b27af5175194d2ba7d0464a08b47393",
      "de66dfaa71454f189a094f2da9311a51",
      "83dee43a1d1f4f4b995907f10f099eed",
      "3d33e1237f0a42cea1c40603a864aa81",
      "f8eab722bd064481a881d8be9f9a6d09",
      "2534a049bf724178ab2807ce33469b27",
      "1a9a0dc3c30345b0aad5db6ec7d1bfd2",
      "62e589f80832420e83ef34024ebc94ad",
      "d6d908b261db4a3f963443da70d35aeb",
      "80d181eec53d4faa9a6c7795feff793a",
      "639c217d7b0d4bf6a0abbf84fef55151",
      "fe30e44fde0e4e1591a5ab7c2e36969d",
      "6b637513f1e64922b8b30466b89091e3",
      "61d32e1e896e4e1bac8ac0bc301f19ee",
      "f43aee3c000c4e4a87a31138d2b2c05d",
      "ca27c1c7802c44bf83804897ae253806",
      "a6cc61de74db4db4a10522624e2dbca6",
      "6195fab013a6464abe686811a3bf46e2",
      "86d0160905e6455091515c045773c5f3",
      "647d433f474d4cc6aa674d16fe16385c",
      "67297f24380843ce9e09c519c9a6c53f",
      "497a798eca0c4c5bac745a7826d1cce6",
      "0088660b28634155a0da2b78ebfe67b0",
      "824d598e66e642a089539a22dc56629c",
      "b65a5ee53b464853b5c678a84f5f1703",
      "3af2f154c02f4c21af7fd624440a7107",
      "0da60820cc894a69b69e7244c67d52da",
      "756a7f039940480c949591ac36af75f6",
      "f90bfeafad3c4f84aeff7945cc7acebb",
      "7c8395dca01844feb506e7e694472625",
      "be330e526595441884f26d0f80eba534",
      "fcce2b89cdf5470ab8d5028d847ae113",
      "b6bf308e0af14e16a68310cb56dea83a",
      "ab9e4f80ef5945d9ad493eb1658371db",
      "b5e04bb13f554366b1b54266d3089246",
      "d7ad9e8ef1834fee8d29bed34f8cfaa4",
      "1d02cac310534975a4b0d2e450d4da6a",
      "12c890d237f740b7ade7a32fb8931219",
      "ea35a617dd05499aa2dad12f9a1bb1b6",
      "d786baf74ec84cc598a64e18e4291101",
      "130cc8808c704ccd870f655d2de13859",
      "ab95e38a54ec4663906c36c1a5f2bebb",
      "c8f04ffe245641219d6ae2d09f9ba6ad",
      "d9f519ecb2224dadb3e82eb6d624db40",
      "28d836ccc633407985489fe6355461c0",
      "38bc1a731c0945c0955b5ea29be950f9",
      "e46abaa2696345599f2d7e518e9c1273",
      "8d5f5a8df0054a59a8805312879d5cc1",
      "891f677eb9be4db2883d8e08ba3565d5",
      "deb895ac9fe0421a9a279086fad33dd9",
      "d585f82d0ba342468a3878c8258053ec",
      "4338f4d2804a49f8ab66348c0f5ec260",
      "04203799667a4f08a9def9a2c3bb5408",
      "8cde3f82de794e3ea5f237fe2e962dee",
      "b3cedb9f6147448e882143fb59aec34a",
      "d08792dfb9f14954b46d3efa2b505db3",
      "a1e4543a89074350b496affdc74214db",
      "6322a66f8894431aa421b57313e66aee",
      "e90264d1406041479e2e7792072169b9",
      "3aa77b0f3a4d4364a1e49af1b000d6d7",
      "038a4200040944eea28ef5566184d1b3",
      "fb23aded39924af9880b0ebe90de1854",
      "3e7f5172621246b7a4a3da2dc57f79bf",
      "72d9649ff71647b59d8e63e4f257db93",
      "b5e6bd3fedd44b3298dc97401919bcbd",
      "a46ba8ebe48b4b45b9f55909c44b5247"
     ]
    },
    "id": "wNkWu1mZB_IA",
    "outputId": "d03ef0ac-33df-46c0-9d80-c6f8fedbf626"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b27af5175194d2ba7d0464a08b47393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe30e44fde0e4e1591a5ab7c2e36969d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0088660b28634155a0da2b78ebfe67b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9e4f80ef5945d9ad493eb1658371db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d836ccc633407985489fe6355461c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08792dfb9f14954b46d3efa2b505db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Hugging Face (Abstractive) Summary ###\n",
      "The TextRank algorithm is an unsupervised, graph-based ranking model for text processing. It works by building a graph where sentences are nodes (vertices) and the edges between them are weighted by semantic similarity.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers sentencepiece torch\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained Abstractive Model (e.g., BART fine-tuned on CNN/DailyMail)\n",
    "# 'summarization' task pipeline automatically loads a default model if one isn't specified.\n",
    "# A common model is 'facebook/bart-large-cnn' or 'google/pegasus-xsum'\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "text = \"\"\"\n",
    "The TextRank algorithm is an unsupervised, graph-based ranking model for text processing.\n",
    "It works by building a graph where sentences are nodes (vertices) and the edges between\n",
    "sentences are weighted by their semantic similarity. This similarity is often calculated\n",
    "using techniques like cosine similarity on word vectors. The process then applies an\n",
    "algorithm similar to PageRank to rank the importance of each sentence. The sentences\n",
    "with the highest scores are extracted to form the final summary. This approach is highly\n",
    "efficient as it avoids the need for massive labeled training data and complex deep learning\n",
    "architectures, making it a reliable choice for legal or technical documents where factual\n",
    "accuracy is paramount.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the summary\n",
    "abstractive_summary = summarizer(\n",
    "    text,\n",
    "    max_length=50,\n",
    "    min_length=10,\n",
    "    do_sample=False\n",
    ")[0]['summary_text']\n",
    "\n",
    "print(\"\\n### Hugging Face (Abstractive) Summary ###\")\n",
    "print(abstractive_summary)\n",
    "# Output will be newly generated, paraphrased sentences."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
