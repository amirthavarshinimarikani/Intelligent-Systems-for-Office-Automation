{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5d4c4cc7b492403891463c97620013a5",
      "ae14e4e2f295422fb8b1c2ccad4c698f",
      "aad15a3d1edf4d47b29903ea9f18c397",
      "18611c6d4b2043e3b0aff32436cc1b07",
      "80af99a7343d425b85943933a329876b",
      "051b2742b67a4fb3a038be1d7b6516c1",
      "529e3eb350ce4602906aa440ec7a0eee",
      "15e5dc4c34364669b52f2a50cc4d87c2",
      "55d39eabe11046e184a1904af5fda07a",
      "46677d21ea274722b616462099e4caa4",
      "365f6157648d446085bd5a015267dec5",
      "851e6eca9dc14d7ba04a0d84d7e31df7",
      "22debdfd92ae4cc780a483d2ac996135",
      "ceec941d43ab47959f59a59a2c674281",
      "10dc80a5d0844e0a8d05491b88cd26b1",
      "58a54872f893417fb94db0881239da89",
      "418364ba827b44e8a1a7036ae90c3a29",
      "a567a57675844aea8c5f12dd5436e144",
      "9c37ec58e050472a8bff4644e5464f3b",
      "c31cb0329ceb456d9bc487b3cffdad09",
      "99e4707675254a6ba05ffa731ceb6919",
      "b832c3f8d2fe420b86dc48c166d459ac",
      "0305e8a1d2a2416e92ee3512fd18714a",
      "d9b220a9f1884fa9b34d0c3698c78b18",
      "088d5f4547a14556b5941a9782816f79",
      "d732bec946f548d4a662a87e2b28f88a",
      "3a3f5653830d4ac788e88eced65a5ba3",
      "ca602d2064a54f2c8e310e1442f6b47c",
      "69f5c0537c2c417fbd3b04c81ae6bf63",
      "f324eabae89a4ac9b968d1cd2a48807f",
      "68cc120cddee419cae431ff0fa29be89",
      "7baddcd485c04209b84886f696b83d1f",
      "6b117230fabb49ca8710d5eb28f24aa7",
      "98a84faa67354742be7eec8f45fa514d",
      "179c2e3d55b1433fa4b68a2c01057814",
      "0ea2ef6e64854b6db308f9df31021071",
      "4d1e05d829e54cd7bb910e195a825412",
      "4b55748d7f89459aad604683cc58988a",
      "0fa5a87d743b4f66a756122a5dcf277d",
      "59f8c7d01de5407bb8baf1f2ea4d78d4",
      "f0f819cad11f4050b70c73783c9cd6ef",
      "824508e425504f7dbc57eed576703a86",
      "f399b5dcb7714429afcceb22a81fd4d9",
      "3e426f3688b54c3183b7353d2a9e9306",
      "1cc7d53cc3204dc78dc23e8eb976e917",
      "ea096a7e16ca412fa526f9672466c793",
      "c5435b0a9d564b70b2d0ee1de2b2c066",
      "e515f2d16455462793e942e1232fd989",
      "054146a463d44c8bb50d02ac08cb3fac",
      "b4d8204a91fb44dcb9c9e106e609e0f4",
      "ade93e68d71f41a38ee2de7bc41bdd5a",
      "31fac49635a049cf9ce7111b1c715c03",
      "fab32be508344b5fb288292b7d509dff",
      "59765c85674a4602b1e195e11bf5a92d",
      "678dbbc400c948a4b8a144cd14c167c0",
      "bed05d35bdaa4da29cafb1d547b8ac11",
      "96375f6d77044ebf97257668a7551a0a",
      "4eb7f713f5a044eba3f579796ddb9870",
      "0b7c57faa8c3480fb5eaa443200805be",
      "6d56ac4dff764dcc9adc9bf022761a16",
      "6b5f262d791e4ddba5e180d7b1b42ddb",
      "b06dff72756d4747b2e68d9999217080",
      "367d6f1a13774d4a80fac5b5587345bd",
      "80188c07e0b14e5991100b5ec82c45c2",
      "7bebf5f611c54312a0bfb923383f8a89",
      "47481292bdac45faa1a3c6bf85342648",
      "4e85c4829576481abdd35d3df59beabb",
      "34857a184366446c88f97e180ec904a5",
      "4a71ef43f27746e9bb2982091a14d3f7",
      "bb07c29105104bd596473c49d7e9e814",
      "3a82593372604fd1b4f00c8dfb3aabea",
      "b96257d887224958bbd4f61970e78039",
      "15923adda25a43efafbb113ad386d879",
      "476a96291446465c987439834b95b619",
      "2a4ccfa0381c41628cedb14a7f845c71",
      "ff46f65477b14506ba63d8dc81f6b10e",
      "47962db8080c4c7697852fe17d65c47c",
      "5d2629944231485480675100ff4f872a",
      "60214b43a7b243059b5cb789a148c7a6",
      "706356d62c3646238d44b07321e24a45",
      "c1aa8b46c99745a1becdcca7f0711781",
      "ae0dc3c881c34d5f92c4a5845d904516",
      "45f8114da07248b1bf9333d7d7d5debb",
      "183cce21d3594b46a38552863d339878",
      "fec4419decb640d9882bb5c897b1e731",
      "c428f8a85475413b8e0f1fd15879dcec",
      "f4efb392db1744ebb6629cd3399057e3",
      "10ebfdebe23a4caa9223b1c440d03af9",
      "a7d52c26fa864eb4b9ab957f4d5286ff",
      "e02821a623a34ab39986d198c7da316a",
      "4ca5a868ed1649d2bf5ea74ff8b6fffb",
      "90ced2a0ceee44b9a4c827abc9f04c2a",
      "2b02d4207dab4547b4bcdce9f4e39dc3",
      "f19cd9ba101d40e2be549c2a433c3870",
      "a176e43f1ad849baa205863b1dfac81f",
      "92198699d8314db1b0f86329ac9806b6",
      "bbcd3af46c234526aaa5f11643be1fe9",
      "340ea0f3131446288e61bad0078812b8",
      "a23876e2b0ea4f62aa1fd0a2b6944b7f",
      "8ce55acacbbb4238a83dc6cc6b2ca7e6",
      "a2f351ae519c44d69e6e8a6204e8a357",
      "2b9a9dc47ca54d7fbffd6df8b79443bf",
      "c2d96e55cd4d4c738f434d14d99a247b",
      "f0768d841e7e46cfabf050d0a8e98366",
      "aa415e9164c34251ba7b2bf438ad8171",
      "62616a8739324d92a9532e9dba0d368a",
      "1e38551a16f645c6b65f0cbc08b2b333",
      "f6753cc77430489681eb9d417638b8fd",
      "563d6458214a4f48a4b3b03e6b03e872",
      "f47da7bc8fc1484fb1eb2ab8e899ee00",
      "d2ba897898384a7b9e8002abc86fe5d2",
      "b23ec7f2ac6c4dbd8c897f7a5d284d84",
      "49415881cf194069be3188307681652f",
      "efab3dc2c4e74f19a4a4cbbaf629efc3",
      "2c1fc35ea2544be5b6d18e9883a16bb7",
      "dd554eca96db41ccb86d1105c065223d",
      "ff4bbd304f914b26b591323a70c50ebc",
      "2e87fff6b77649bfbb76346a554115ce",
      "ca8e116c623943d5920aaccc7a46feb1",
      "5f321695fdea4714940b7bd2f10632e2",
      "8010e151a40843adad00b4f2f84b0688"
     ]
    },
    "id": "y8X_uSeRTveF",
    "outputId": "bf3c4466-916a-40e6-a772-718bfa417cbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4c4cc7b492403891463c97620013a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851e6eca9dc14d7ba04a0d84d7e31df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0305e8a1d2a2416e92ee3512fd18714a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a84faa67354742be7eec8f45fa514d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc7d53cc3204dc78dc23e8eb976e917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed05d35bdaa4da29cafb1d547b8ac11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e85c4829576481abdd35d3df59beabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2629944231485480675100ff4f872a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d52c26fa864eb4b9ab957f4d5286ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce55acacbbb4238a83dc6cc6b2ca7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ba897898384a7b9e8002abc86fe5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Question</th>\n",
       "      <th>Retrieval-Based Answer</th>\n",
       "      <th>Similarity Score</th>\n",
       "      <th>Generative Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is the CEO of Tesla?</td>\n",
       "      <td>Elon Musk is the CEO of Tesla.</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Elon Musk is the CEO of Tesla.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tell me about the capital of France</td>\n",
       "      <td>The capital of France is Paris.</td>\n",
       "      <td>0.928</td>\n",
       "      <td>The capital of France is Paris. It is known for its rich history, iconic landmarks such as the Eiffel Tower and the Louvre Museum, as well as its renowned cuisine and fashion industry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which planet is the biggest?</td>\n",
       "      <td>Jupiter is the largest planet in our solar system.</td>\n",
       "      <td>0.950</td>\n",
       "      <td>Jupiter is the largest planet in our solar system.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who wrote Hamlet?</td>\n",
       "      <td>Hamlet was written by William Shakespeare.</td>\n",
       "      <td>1.000</td>\n",
       "      <td>The play \"Hamlet\" was written by William Shakespeare.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Explain machine learning in simple words.</td>\n",
       "      <td>Machine learning is a field of AI that enables systems to learn from data.</td>\n",
       "      <td>0.780</td>\n",
       "      <td>Machine learning is a type of artificial intelligence that teaches computers to learn and make decisions without being explicitly programmed. Essentially, it involves creating algorithms and models that allow machines to improve their performance on a task over time by learning from data.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===============================\n",
    "# üì¶ INSTALL DEPENDENCIES\n",
    "# ===============================\n",
    "!pip install transformers sentence-transformers faiss-cpu openai\n",
    "\n",
    "# ===============================\n",
    "# üîß IMPORTS\n",
    "# ===============================\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# ===============================\n",
    "# üß≠ 1. RETRIEVAL-BASED CHATBOT\n",
    "# ===============================\n",
    "\n",
    "# Create a small FAQ-style knowledge base\n",
    "knowledge_base = [\n",
    "    {\"question\": \"What is the capital of France?\", \"answer\": \"The capital of France is Paris.\"},\n",
    "    {\"question\": \"Who is the CEO of Tesla?\", \"answer\": \"Elon Musk is the CEO of Tesla.\"},\n",
    "    {\"question\": \"What is machine learning?\", \"answer\": \"Machine learning is a field of AI that enables systems to learn from data.\"},\n",
    "    {\"question\": \"What is the largest planet?\", \"answer\": \"Jupiter is the largest planet in our solar system.\"},\n",
    "    {\"question\": \"Who wrote Hamlet?\", \"answer\": \"Hamlet was written by William Shakespeare.\"},\n",
    "]\n",
    "\n",
    "# Load an embedding model for semantic similarity\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Precompute question embeddings\n",
    "kb_embeddings = embedder.encode([item[\"question\"] for item in knowledge_base], convert_to_tensor=True)\n",
    "\n",
    "def retrieval_based_chatbot(user_query):\n",
    "    # Encode the user query\n",
    "    query_embedding = embedder.encode(user_query, convert_to_tensor=True)\n",
    "    # Find the most similar question\n",
    "    hits = util.semantic_search(query_embedding, kb_embeddings, top_k=1)\n",
    "    best_match = hits[0][0]\n",
    "    best_index = best_match[\"corpus_id\"]\n",
    "    best_score = best_match[\"score\"]\n",
    "    # Return matched answer\n",
    "    return knowledge_base[best_index][\"answer\"], best_score\n",
    "\n",
    "# ===============================\n",
    "# üß† 2. GENERATIVE CHATBOT (GPT)\n",
    "# ===============================\n",
    "\n",
    "# ‚ö†Ô∏è Replace YOUR_API_KEY with your actual OpenAI API key\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# üîë Your OpenRouter API key\n",
    "OPENROUTER_API_KEY = \"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\"  # keep this safe!\n",
    "\n",
    "def generative_chatbot(user_query):\n",
    "    prompt = f\"You are a helpful assistant. Answer this question clearly: {user_query}\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo\",  # or \"gpt-4-turbo\", \"meta-llama/llama-3.1-70b-instruct\"\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a concise and factual question-answering assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://openrouter.ai/api/v1/chat/completions\", headers=headers, data=json.dumps(data))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    else:\n",
    "        return f\"‚ö†Ô∏è Error: {response.status_code}, {response.text}\"\n",
    "\n",
    "# ===============================\n",
    "# üîç 3. TEST BOTH CHATBOTS\n",
    "# ===============================\n",
    "user_queries = [\n",
    "    \"Who is the CEO of Tesla?\",\n",
    "    \"Tell me about the capital of France\",\n",
    "    \"Which planet is the biggest?\",\n",
    "    \"Who wrote Hamlet?\",\n",
    "    \"Explain machine learning in simple words.\"\n",
    "]\n",
    "\n",
    "retrieval_results, generative_results = [], []\n",
    "\n",
    "for q in user_queries:\n",
    "    r_ans, score = retrieval_based_chatbot(q)\n",
    "    g_ans = generative_chatbot(q)\n",
    "    retrieval_results.append((q, r_ans, round(score, 3)))\n",
    "    generative_results.append((q, g_ans))\n",
    "\n",
    "# ===============================\n",
    "# üìä 4. VISUAL COMPARISON\n",
    "# ===============================\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "data = []\n",
    "for i, q in enumerate(user_queries):\n",
    "    data.append({\n",
    "        \"User Question\": q,\n",
    "        \"Retrieval-Based Answer\": retrieval_results[i][1],\n",
    "        \"Similarity Score\": retrieval_results[i][2],\n",
    "        \"Generative Answer\": generative_results[i][1]\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "display(HTML(df.to_html(escape=False)))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
