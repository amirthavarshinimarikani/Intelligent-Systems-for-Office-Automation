{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365,
     "referenced_widgets": [
      "2787d60d9b814b02af09f3faa2b01167",
      "3fc09a77c68740ada02008de81976663",
      "2703ac02b69043e8a755b71c6143ae6b",
      "6bfc53925d9b4d6a8a8221a48f9fc572",
      "529931553c254d9ea2d3ffafe4be3645",
      "79e98b9866524f75b884d242c1ac3171",
      "5638667e58124d58b2fc5719ac2182bf",
      "739c38c0805b438e98813f28b626a160",
      "f4500a658a0842b184b0e64e6373f565",
      "0a6c3661846b4603acbbe84053b33f9d",
      "ae61d6f6b3374649bbdc5e6b761c9068",
      "9382ebd10ecc45a1b6107d150ea3a841",
      "57ea12d2cdcf4492b9a5e93911df9514",
      "bbf50470c2d8430381da9b44e1e5fa3a",
      "72bf967d7c9246759bc4d72e9ea4f312",
      "6a439fa89661460d9845d458f6c08f75",
      "a0b079bf054a47cc875e5d8d969f5f58",
      "7065ee66e788425fab3fab44c214f355",
      "2f3638affedd4b18a5ba2654dbac5bca",
      "00bd730d3d9647e4b480bf067f28f5fb",
      "fe28be25cbd54d689351093eb928c361",
      "b5a64b4a0ccd485283f3b9e5a8753bb8",
      "bc402dd43aec4c7d9623ac8540c7792d",
      "5d655822e20b4a9ab229f099332743a4",
      "be6554db244b4cdb89896432b43e4f52",
      "b0719565c9f545ac8add96f1f639fad3",
      "d7d18533c5ff498f9e1cb08ae077d8af",
      "3f51ee644f76406a97e6245fda50ec1a",
      "943ee03143a64fe8877ebbd37bd2e7f1",
      "8e428cf0bfe04991b2a2fd0a3dd61ce6",
      "4d6d7ebf41bf4ca5945e56bf97f1e742",
      "3ec50dcd344348dd80279fa8c1c24d6c",
      "daf4afd9a77648cc9bb7085ce5fb5ee7",
      "da9baa392d8f4451a9efc2c4bab445f8",
      "2bc156334ca34689a96818872ee5eb59",
      "da7ddc97404745f5815fad5a4c3b4c95",
      "61469a0c6989498a9ab0ee0b474302dc",
      "951fd565b1bf469c845001a50d9dbce3",
      "005e8d3814c34bb1b536e5cb3d598a3d",
      "568cf1c8b6394dcc91f5d5fb7002c9c3",
      "f0796028a12545eb92cd5713085c5f72",
      "fa050b8332f54219a90467131f1fa18e",
      "cd36a0f4eff04882993250e2624e4701",
      "829ccc69c5cb41999f855764d4ba97af",
      "6f099933b90948b498f5222903b5c20c",
      "98d10ed66ac042eabb1b5f11bcc96a32",
      "ee27a3bcffd74307b21aa6bea38b3b45",
      "69b71c3e2123449e9c977771978f94f8",
      "5a675ce9662f4353aeb1a75aedce99ea",
      "cc132939c7d140878d953b46c585c829",
      "071cc9d7760243a09f1a14eebf363d50",
      "1cd9b948cd3045849f5ed9305b92a5d8",
      "2e3dbbe0b0174d28ad09ea9835cc888f",
      "414c17c1979e42d6940f8a93bb0aab23",
      "8c00d239f6b14f0885227b653ec34f48",
      "876937165c8b4445955c1fe1b21176ce",
      "665e555bea1841b8acfdc1d38579fef8",
      "0352e682bcef462dbf1fedf02a0e4650",
      "b12950975ac048f38df78dbfd3758598",
      "a9e2a761606f442985b3b25542766edd",
      "bf7bc18eee1942ef977591601fd39ef9",
      "f938a2b70c4c488e9e75b93ac7fd9dfb",
      "18fa03ec5e4f45cc9dad7f5a73e5fa9e",
      "9a9152fc93504da8992f6773e644e619",
      "b2bc4d01c87c4d4d8f15c9b670f07d40",
      "76cbedf5558748dab85d47b8668a2549"
     ]
    },
    "id": "Uc8ZILBuRATn",
    "outputId": "6fb026ae-282f-4e51-b7b9-5bf796037631"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2787d60d9b814b02af09f3faa2b01167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9382ebd10ecc45a1b6107d150ea3a841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc402dd43aec4c7d9623ac8540c7792d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9baa392d8f4451a9efc2c4bab445f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f099933b90948b498f5222903b5c20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876937165c8b4445955c1fe1b21176ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.5291890777880326, 'start': 1, 'end': 22, 'answer': 'The Amazon rainforest'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load pre-trained QA pipeline using RoBERTa fine-tuned on SQuAD2.0\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=\"deepset/roberta-base-squad2\"\n",
    ")\n",
    "\n",
    "# Example context and question\n",
    "context = \"\"\"\n",
    "The Amazon rainforest is the largest tropical rainforest in the world,\n",
    "covering over five and a half million square kilometers.\n",
    "\"\"\"\n",
    "question = \"What is the largest tropical rainforest in the world?\"\n",
    "\n",
    "# Get answer\n",
    "result = qa_pipeline(question=question, context=context)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
